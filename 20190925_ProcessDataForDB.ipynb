{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReadMe\n",
    "\n",
    "**This is the notebook to import the data from K/I/whatever the driver is and send raw/cleaned data to a postgresql DB on powerplant.\n",
    "\n",
    "**Plan:\n",
    "\n",
    "1. Read data in\n",
    "2. Select down to right TDR measurments\n",
    "3. Send the raw data from each tdr to DB - this is for examing the suprise values \n",
    "4. Clean out missing and stupid high values\n",
    "5. Average the value in each layer (7 layers in total)\n",
    "6. Calculate deficit \n",
    "7. Upload the calculated deficit to DB - for real irrigation scheduling - need to be a separate table \n",
    "\n",
    "**PostgreSQL credentials\n",
    "\n",
    "    host = \"database.powerplant.pfr.co.nz\",\n",
    "    database = \"cflfcl_Rainshelter_SWC\",\n",
    "    user = \"cflfcl_Rainshelter_SWC\",\n",
    "    password = \"o654UkI6iGNwhzHu\"\n",
    "    \n",
    "**Format that `sqlalchemy` like\n",
    "    \n",
    "    \"postgresql://cflfcl_Rainshelter_SWC:o654UkI6iGNwhzHu@database.powerplant.pfr.co.nz/cflfcl_Rainshelter_SWC\"\n",
    "    \n",
    "**Demo data source\n",
    "\n",
    "    K:\\Rainshelter\\StonySoilLysimeters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"K:/Rainshelter/StonySoilLysimeters/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the main data\n",
    "AllData=pd.read_csv(path + 'DownloadedData/StonyLysimetersCS650.dat', #specify file path for data to read in\n",
    "                         parse_dates=True, #tell the function to parse date columns to datetime formats\n",
    "                         dayfirst=True, #tell the function that the day is before the year in the data i.e format='%d/%m/%Y %H:%M'\n",
    "                         skiprows = [0,2,3], #leave out rows 1, 3 and 4 which have redundant information\n",
    "                         index_col = 0, #Use the first column, which is Date, as an index\n",
    "                         na_values = 'NAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The index for sensors\n",
    "AllDataIndex = pd.read_excel(path + \"Lysometer_design.xlsx\",\n",
    "                             sheet_name=\"SensorIndex\",\n",
    "                             index_col = 0)\n",
    "AllDataIndex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the part that interested in \n",
    "FilteredIndex=AllDataIndex[AllDataIndex.Measurement.isin(['VolumetricWaterContent'])] # structure to add in more cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilteredIndex.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilteredIndex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the interested columns \n",
    "FilteredData=AllData.loc[:,FilteredIndex.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the index and output the last row \n",
    "FilteredDataTrans=FilteredData.transpose() # transpose to the format match the index format\n",
    "FilteredDataIndexed=pd.concat([FilteredIndex,FilteredDataTrans], axis=1) # join them together\n",
    "\n",
    "FilteredDataIndexed.index.name='ColumnHeader'\n",
    "FilteredDataIndexed.set_index(['Measurement','Depth','Gravels','Stones','Column','Sensor', 'MUX', 'Port','Units','Summary','Block','Treatment'], \n",
    "                        append=False, inplace=True)\n",
    "FilteredDataIndexed.sort_index(inplace=True)\n",
    "# FieldData=FilteredDataIndexed.transpose()\n",
    "# FieldData.index = pd.to_datetime(FieldData.index) \n",
    "# LastRow = FieldData.index.size\n",
    "# np.save('LastRow.npy',LastRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilteredDataIndexed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilteredDataIndexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last filter to get ready upload the raw \n",
    "grouped=FilteredDataIndexed.groupby(level='Measurement',axis=1).mean().round(2)\n",
    "# is not actually calculate any mean, just want to see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB connection and uploading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FieldData.dtypes\n",
    "# FieldData.index\n",
    "engine = create_engine(\"postgresql://cflfcl_Rainshelter_SWC:o654UkI6iGNwhzHu@database.powerplant.pfr.co.nz/cflfcl_Rainshelter_SWC\")\n",
    "grouped.to_sql(name=\"RawData_96Sensors\",con=engine,if_exists='replace' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place holder for `.csv` index file\n",
    "# AllDataIndex=pd.read_csv('./IndexFiles/SoilWaterAndTempIndex.csv',\n",
    "#                          index_col = 0)\n",
    "# AllDataIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Deficit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataMeans =  FieldData.loc['2015-10-10':].groupby(level=['Measurement','Depth','Gravels','Stones'],axis=1).mean()\n",
    "DataMeans =  DataMeans.dropna(axis=1) #For some reason it keeps non valid combinations in so need to extract with this function\n",
    "ProfileWater = DataMeans.VolumetricWaterContent.loc[:, 'D1'] * 150 + \\\n",
    "               DataMeans.VolumetricWaterContent.loc[:, 'D2'] * 150 + \\\n",
    "               DataMeans.VolumetricWaterContent.loc[:, 'D3'] * 150 + \\\n",
    "               DataMeans.VolumetricWaterContent.loc[:, 'D4'] * 150 \n",
    "FieldCapacity = ProfileWater.resample('D').max()\n",
    "FieldCapacity = FieldCapacity.loc['2015-10-14'] +10 # I would have though this would return a data frame with a single row but instead it returns a series with a multiindex in columns\n",
    "SoilWaterDeficit = -(FieldCapacity - ProfileWater)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoilWaterDeficit.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading \n",
    "SoilWaterDeficit.to_sql(name=\"SoilWaterDeficit\",con=engine, if_exists ='replace')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
